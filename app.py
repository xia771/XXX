import streamlit as st
from PIL import Image
import torch
import cv2
import numpy as np
from ultralytics import YOLO
import time
import os
from datetime import datetime
import pandas as pd

# è®¾ç½®é¡µé¢é…ç½®
st.set_page_config(
    page_title="å®‰å…¨å¤´ç›”æ£€æµ‹ç³»ç»Ÿ",
    page_icon="ğŸª–",
    layout="wide",
    initial_sidebar_state="expanded"
)

# è‡ªå®šä¹‰CSSæ ·å¼
st.markdown("""
    <style>
        .stButton>button {
            width: 100%;
            background-color: #ff4b4b;
            color: white;
        }
        .stButton>button:hover {
            background-color: #ff6b6b;
        }
    </style>
""", unsafe_allow_html=True)

# åŠ è½½æ¨¡å‹
@st.cache_resource
def load_model(model_path):
    return YOLO(model_path)

# æ¨¡å‹é€‰æ‹©
available_models = [f for f in os.listdir('.') if f.endswith('.pt')]
model_path = 'best.pt' if 'best.pt' in available_models else available_models[0] if available_models else None

if not model_path:
    st.error("æœªæ‰¾åˆ°å¯ç”¨çš„æ¨¡å‹æ–‡ä»¶ï¼")
    st.stop()

# ä¸»ç•Œé¢
st.title("ğŸª– å®‰å…¨å¤´ç›”æ£€æµ‹ç³»ç»Ÿ")
st.markdown(f"å½“å‰ä½¿ç”¨æ¨¡å‹: `{model_path}`")

# ä¾§è¾¹æ é…ç½®
with st.sidebar:
    st.title("âš™ï¸ ç³»ç»Ÿé…ç½®")
    
    st.markdown("---")
    
    # æ£€æµ‹æ¨¡å¼é€‰æ‹©
    detection_mode = st.selectbox(
        "é€‰æ‹©æ£€æµ‹æ¨¡å¼",
        ["ğŸ“¸ å•å¼ å›¾ç‰‡æ£€æµ‹", "ğŸ“ æ‰¹é‡å›¾ç‰‡æ£€æµ‹", "ğŸ“‚ æ•°æ®é›†æ–‡ä»¶å¤¹æ£€æµ‹", "ğŸ¥ å®æ—¶è§†é¢‘æ£€æµ‹", "ğŸ“¹ è§†é¢‘æ–‡ä»¶æ£€æµ‹"],
        help="é€‰æ‹©è¦ä½¿ç”¨çš„æ£€æµ‹æ¨¡å¼"
    )
    
    st.markdown("---")
    
    # æ¨¡å‹é€‰æ‹©
    model_path = st.selectbox(
        "é€‰æ‹©æ£€æµ‹æ¨¡å‹",
        available_models,
        index=available_models.index('best.pt') if 'best.pt' in available_models else 0
    )
    
    confidence = st.slider("ç½®ä¿¡åº¦é˜ˆå€¼", 0.0, 1.0, 0.01, 0.01)
    
    # é«˜çº§è®¾ç½®æŠ˜å é¢æ¿
    with st.expander("ğŸ› ï¸ é«˜çº§è®¾ç½®"):
        iou_threshold = st.slider("IOUé˜ˆå€¼", 0.0, 1.0, 0.45, 0.01)
        max_det = st.number_input("æœ€å¤§æ£€æµ‹æ•°é‡", 1, 100, 20)
    
    st.markdown("---")
    st.markdown("""
    ### ğŸ’¡ ä½¿ç”¨è¯´æ˜
    1. é€‰æ‹©åˆé€‚çš„æ£€æµ‹æ¨¡å‹
    2. è°ƒæ•´ç½®ä¿¡åº¦é˜ˆå€¼ï¼ˆå€¼è¶Šå°æ£€å‡ºç‡è¶Šé«˜ï¼‰
    3. é€‰æ‹©æ£€æµ‹æ¨¡å¼ï¼ˆå›¾ç‰‡/è§†é¢‘ï¼‰
    """)

# åŠ è½½é€‰æ‹©çš„æ¨¡å‹
model = load_model(model_path)

if detection_mode == "ğŸ“¸ å•å¼ å›¾ç‰‡æ£€æµ‹":
    uploaded_file = st.file_uploader("é€‰æ‹©å›¾ç‰‡", type=['png', 'jpg', 'jpeg'])
    
    if uploaded_file is not None:
        try:
            # è¯»å–å›¾ç‰‡
            image = Image.open(uploaded_file)
            img_array = np.array(image)
            
            # åˆ›å»ºä¸¤åˆ—å¸ƒå±€
            col1, col2 = st.columns(2)
            
            with col1:
                st.subheader("ğŸ“¸ åŸå§‹å›¾ç‰‡")
                # ç¡®ä¿å›¾ç‰‡æ˜¯RGBæ ¼å¼
                if image.mode != 'RGB':
                    image = image.convert('RGB')
                st.image(image, caption=f"æ–‡ä»¶å: {uploaded_file.name}")
            
            with col2:
                st.subheader("ğŸ¯ æ£€æµ‹ç»“æœ")
                start_time = time.time()
                # è¿›è¡Œé¢„æµ‹
                results = model(img_array, conf=confidence, iou=iou_threshold, max_det=max_det)
                end_time = time.time()
                
                # åœ¨å›¾ç‰‡ä¸Šç»˜åˆ¶æ£€æµ‹ç»“æœ
                for result in results:
                    plotted = result.plot()
                    st.image(plotted, caption="æ£€æµ‹ç»“æœ")
                    
                    # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
                    if len(result.boxes) > 0:
                        st.success(f"âœ… æ£€æµ‹åˆ° {len(result.boxes)} ä¸ªç›®æ ‡")
                        
                        # åˆ›å»ºæ£€æµ‹ç»“æœè¡¨æ ¼
                        results_data = []
                        for i, box in enumerate(result.boxes):
                            confidence = box.conf.item()
                            results_data.append({
                                "ç›®æ ‡ç¼–å·": i + 1,
                                "ç½®ä¿¡åº¦": f"{confidence:.2%}",
                                "åæ ‡": f"({int(box.xyxy[0][0])}, {int(box.xyxy[0][1])}, {int(box.xyxy[0][2])}, {int(box.xyxy[0][3])})"
                            })
                        
                        st.table(results_data)
                    else:
                        st.warning("âš ï¸ æœªæ£€æµ‹åˆ°ç›®æ ‡")
                    
                    st.info(f"âš¡ æ£€æµ‹ç”¨æ—¶: {(end_time - start_time):.3f} ç§’")
        except Exception as e:
            st.error(f"å¤„ç†å›¾ç‰‡æ—¶å‡ºé”™: {str(e)}")
    
elif detection_mode == "ğŸ“ æ‰¹é‡å›¾ç‰‡æ£€æµ‹":
    uploaded_files = st.file_uploader("é€‰æ‹©å¤šå¼ å›¾ç‰‡", type=['png', 'jpg', 'jpeg'], accept_multiple_files=True)
    
    if uploaded_files:
        st.info(f"å·²ä¸Šä¼  {len(uploaded_files)} å¼ å›¾ç‰‡")
        
        # æ‰¹é‡å¤„ç†è¿›åº¦æ¡
        progress_bar = st.progress(0)
        status_text = st.empty()
        
        # åˆ›å»ºå›¾ç‰‡ç½‘æ ¼å¸ƒå±€
        cols = st.columns(3)
        
        # æ‰¹é‡å¤„ç†å›¾ç‰‡
        for idx, uploaded_file in enumerate(uploaded_files):
            # æ›´æ–°è¿›åº¦
            progress = (idx + 1) / len(uploaded_files)
            progress_bar.progress(progress)
            status_text.text(f"æ­£åœ¨å¤„ç†: {uploaded_file.name} ({idx + 1}/{len(uploaded_files)})")
            
            # è¯»å–å›¾ç‰‡
            image = Image.open(uploaded_file)
            img_array = np.array(image)
            
            # è¿›è¡Œæ£€æµ‹
            start_time = time.time()
            results = model(img_array, conf=confidence, iou=iou_threshold, max_det=max_det)
            end_time = time.time()
            
            # åœ¨å¯¹åº”çš„åˆ—ä¸­æ˜¾ç¤ºç»“æœ
            col_idx = idx % 3
            with cols[col_idx]:
                # åˆ›å»ºä¸€ä¸ªexpanderæ¥æ˜¾ç¤ºæ¯å¼ å›¾ç‰‡çš„è¯¦ç»†ä¿¡æ¯
                with st.expander(f"å›¾ç‰‡ {idx + 1}: {uploaded_file.name}", expanded=True):
                    # æ˜¾ç¤ºåŸå›¾å’Œæ£€æµ‹ç»“æœçš„å¯¹æ¯”
                    col1, col2 = st.columns(2)
                    with col1:
                        st.image(image, caption="åŸå›¾")
                    with col2:
                        for result in results:
                            plotted = result.plot()
                            st.image(plotted, caption="æ£€æµ‹ç»“æœ")
                            
                            # æ˜¾ç¤ºæ£€æµ‹ç»“æœ
                            if len(result.boxes) > 0:
                                st.success(f"æ£€æµ‹åˆ° {len(result.boxes)} ä¸ªç›®æ ‡")
                                # æ˜¾ç¤ºç½®ä¿¡åº¦
                                for i, conf in enumerate([box.conf.item() for box in result.boxes]):
                                    st.text(f"ç›®æ ‡ {i+1} ç½®ä¿¡åº¦: {conf:.2%}")
                            else:
                                st.warning("æœªæ£€æµ‹åˆ°ç›®æ ‡")
                            
                            st.text(f"å¤„ç†æ—¶é—´: {(end_time - start_time):.3f} ç§’")
        
        # å®Œæˆå¤„ç†
        progress_bar.empty()
        status_text.success("âœ… æ‰€æœ‰å›¾ç‰‡å¤„ç†å®Œæˆï¼")
        
elif detection_mode == "ğŸ“‚ æ•°æ®é›†æ–‡ä»¶å¤¹æ£€æµ‹":
    st.markdown("### ğŸ“‚ æ•°æ®é›†æ–‡ä»¶å¤¹æ£€æµ‹")
    
    # è¾“å…¥æ•°æ®é›†è·¯å¾„
    dataset_path = st.text_input("è¾“å…¥æ•°æ®é›†æ–‡ä»¶å¤¹è·¯å¾„", "")
    
    # é«˜çº§è®¾ç½®
    with st.expander("ğŸ› ï¸ é«˜çº§è®¾ç½®"):
        batch_size = st.number_input("æ‰¹å¤„ç†å¤§å°", min_value=1, max_value=32, value=16)
        save_results = st.checkbox("ä¿å­˜æ£€æµ‹ç»“æœ", value=True)
        save_path = st.text_input("ç»“æœä¿å­˜è·¯å¾„", "detection_results") if save_results else None
        recursive_search = st.checkbox("é€’å½’æœç´¢å­æ–‡ä»¶å¤¹", value=True)
        
    if st.button("å¼€å§‹å¤„ç†æ•°æ®é›†") and dataset_path:
        if not os.path.exists(dataset_path):
            st.error("âŒ æ•°æ®é›†è·¯å¾„ä¸å­˜åœ¨ï¼")
        else:
            # è·å–æ‰€æœ‰å›¾ç‰‡æ–‡ä»¶
            image_extensions = ('.jpg', '.jpeg', '.png', '.bmp')
            image_files = []
            
            if recursive_search:
                for root, _, files in os.walk(dataset_path):
                    for file in files:
                        if file.lower().endswith(image_extensions):
                            image_files.append(os.path.join(root, file))
            else:
                image_files = [f for f in os.listdir(dataset_path) 
                             if f.lower().endswith(image_extensions)]
                image_files = [os.path.join(dataset_path, f) for f in image_files]
            
            if not image_files:
                st.warning("âš ï¸ æœªæ‰¾åˆ°å›¾ç‰‡æ–‡ä»¶ï¼")
            else:
                st.info(f"æ‰¾åˆ° {len(image_files)} ä¸ªå›¾ç‰‡æ–‡ä»¶")
                
                # åˆ›å»ºä¿å­˜ç›®å½•
                if save_results and save_path:
                    os.makedirs(save_path, exist_ok=True)
                
                # åˆå§‹åŒ–è¿›åº¦æ¡å’Œè®¡æ•°å™¨
                progress_bar = st.progress(0)
                status_text = st.empty()
                stats_container = st.empty()
                
                # å¤„ç†ç»Ÿè®¡
                processed_count = 0
                detection_count = 0
                processing_times = []
                detection_results = []
                
                # æ‰¹é‡å¤„ç†å›¾ç‰‡
                for i in range(0, len(image_files), batch_size):
                    batch_files = image_files[i:i + batch_size]
                    batch_images = []
                    
                    # è¯»å–æ‰¹æ¬¡å›¾ç‰‡
                    for img_path in batch_files:
                        try:
                            img = cv2.imread(img_path)
                            if img is not None:
                                batch_images.append((img_path, img))
                        except Exception as e:
                            st.error(f"å¤„ç†å›¾ç‰‡ {img_path} æ—¶å‡ºé”™: {str(e)}")
                    
                    # æ‰¹é‡æ£€æµ‹
                    start_time = time.time()
                    results = model([img for _, img in batch_images], 
                                 conf=confidence, 
                                 iou=iou_threshold, 
                                 max_det=max_det)
                    batch_time = time.time() - start_time
                    processing_times.append(batch_time)
                    
                    # å¤„ç†æ¯å¼ å›¾ç‰‡çš„ç»“æœ
                    for (img_path, _), result in zip(batch_images, results):
                        processed_count += 1
                        
                        # è·å–æ£€æµ‹ç»“æœ
                        boxes = result.boxes
                        num_detections = len(boxes)
                        detection_count += num_detections
                        
                        # è®°å½•ç»“æœ
                        detection_results.append({
                            'image': os.path.basename(img_path),
                            'detections': num_detections,
                            'confidences': [box.conf.item() for box in boxes]
                        })
                        
                        # ä¿å­˜ç»“æœ
                        if save_results and save_path:
                            # ä¿å­˜æ ‡æ³¨åçš„å›¾ç‰‡
                            output_path = os.path.join(save_path, os.path.basename(img_path))
                            cv2.imwrite(output_path, result.plot())
                            
                            # ä¿å­˜æ£€æµ‹ç»“æœåˆ°txt
                            txt_path = os.path.splitext(output_path)[0] + '.txt'
                            with open(txt_path, 'w') as f:
                                for box in boxes:
                                    coords = box.xyxy[0].tolist()
                                    conf = box.conf.item()
                                    f.write(f"helmet {conf:.4f} {' '.join(map(str, coords))}\n")
                    
                    # æ›´æ–°è¿›åº¦å’Œç»Ÿè®¡
                    progress = (i + len(batch_files)) / len(image_files)
                    progress_bar.progress(progress)
                    
                    # æ›´æ–°çŠ¶æ€ä¿¡æ¯
                    status_text.text(f"å¤„ç†è¿›åº¦: {processed_count}/{len(image_files)} å›¾ç‰‡")
                    
                    # å®æ—¶ç»Ÿè®¡ä¿¡æ¯
                    stats_container.markdown(f"""
                    ### ğŸ“Š å®æ—¶å¤„ç†ç»Ÿè®¡
                    - å·²å¤„ç†å›¾ç‰‡: {processed_count}/{len(image_files)}
                    - æ£€æµ‹åˆ°çš„ç›®æ ‡: {detection_count}
                    - å¹³å‡æ¯å›¾ç›®æ ‡æ•°: {detection_count/max(1, processed_count):.2f}
                    - æ¯å¼ å›¾ç‰‡å¹³å‡ç”¨æ—¶: {batch_time/len(batch_files):.3f}ç§’
                    """)
                
                # å¤„ç†å®Œæˆï¼Œæ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
                progress_bar.empty()
                status_text.success("âœ… æ•°æ®é›†å¤„ç†å®Œæˆï¼")
                
                # åˆ›å»ºæ£€æµ‹ç»“æœDataFrame
                df = pd.DataFrame(detection_results)

                # æ˜¾ç¤ºç»Ÿè®¡ä¿¡æ¯
                st.markdown("### ğŸ“Š æ£€æµ‹ç»Ÿè®¡åˆ†æ")
                
                col1, col2, col3 = st.columns(3)
                with col1:
                    st.metric("æ€»å¤„ç†å›¾ç‰‡æ•°", processed_count)
                with col2:
                    st.metric("æ€»æ£€æµ‹ç›®æ ‡æ•°", detection_count)
                with col3:
                    avg_detections = detection_count/max(1, processed_count)
                    st.metric("å¹³å‡æ¯å¼ æ£€æµ‹æ•°", f"{avg_detections:.2f}")
                    
                # ä¿å­˜ç»Ÿè®¡ç»“æœ
                if save_results and save_path:
                    # ä¿å­˜ç»Ÿè®¡æŠ¥å‘Š
                    report_path = os.path.join(save_path, 'detection_report.csv')
                    df.to_csv(report_path, index=False)
                    
                    st.success(f"âœ… æ£€æµ‹ç»“æœå·²ä¿å­˜åˆ°: {save_path}")
                    
                    # æä¾›ä¸‹è½½é“¾æ¥
                    with open(report_path, 'rb') as f:
                        st.download_button(
                            label="ğŸ“¥ ä¸‹è½½æ£€æµ‹æŠ¥å‘Š(CSV)",
                            data=f,
                            file_name="detection_report.csv",
                            mime="text/csv"
                        )
    
elif detection_mode == "ğŸ¥ å®æ—¶è§†é¢‘æ£€æµ‹":
    st.warning("âš ï¸ è¯·ç¡®ä¿å·²æˆæƒæ‘„åƒå¤´è®¿é—®æƒé™")
    
    # å¼€å§‹/åœæ­¢æŒ‰é’®
    if st.button('ğŸ¥ å¼€å§‹æ£€æµ‹'):
        cap = cv2.VideoCapture(0)
        
        while True:
            ret, frame = cap.read()
            if not ret:
                st.error("æ— æ³•è®¿é—®æ‘„åƒå¤´")
                break
            
            # è¿›è¡Œæ£€æµ‹
            start_time = time.time()
            results = model(frame, conf=confidence, iou=iou_threshold, max_det=max_det)
            end_time = time.time()
            
            # ç»˜åˆ¶ç»“æœ
            for result in results:
                frame = result.plot()
                
                # æ˜¾ç¤ºå®æ—¶ç»Ÿè®¡
                st.markdown(f"""
                ### ğŸ“Š å®æ—¶ç›‘æµ‹æ•°æ®
                - å½“å‰æ£€æµ‹ç›®æ ‡æ•°: {len(result.boxes)}
                - FPS: {1/(end_time - start_time):.1f}
                """)
            
            # æ˜¾ç¤ºå¸§
            st.image(frame, channels="BGR", caption="å®æ—¶æ£€æµ‹")
            
            # æ§åˆ¶å¸§ç‡
            time.sleep(0.01)
            
        cap.release()
        
    st.markdown("---")
    st.info("ğŸ“ æç¤ºï¼šç‚¹å‡»'å¼€å§‹æ£€æµ‹'æŒ‰é’®å¯åŠ¨æ‘„åƒå¤´æ£€æµ‹ã€‚")
    
else:  # è§†é¢‘æ–‡ä»¶æ£€æµ‹
    uploaded_video = st.file_uploader("é€‰æ‹©è§†é¢‘æ–‡ä»¶", type=['mp4', 'avi', 'mov'])
    
    if uploaded_video is not None:
        # ä¿å­˜ä¸Šä¼ çš„è§†é¢‘æ–‡ä»¶
        video_path = f"temp_video_{int(time.time())}.mp4"
        with open(video_path, "wb") as f:
            f.write(uploaded_video.getbuffer())
        
        # è§†é¢‘å¤„ç†æ§åˆ¶
        if st.button("å¼€å§‹å¤„ç†è§†é¢‘"):
            # æ‰“å¼€è§†é¢‘æ–‡ä»¶
            cap = cv2.VideoCapture(video_path)
            total_frames = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))
            fps = int(cap.get(cv2.CAP_PROP_FPS))
            
            # åˆ›å»ºè¿›åº¦æ¡å’ŒçŠ¶æ€æ˜¾ç¤º
            progress_bar = st.progress(0)
            status_text = st.empty()
            frame_placeholder = st.empty()
            stats_placeholder = st.empty()
            
            frame_count = 0
            detection_results = []
            
            while cap.isOpened():
                ret, frame = cap.read()
                if not ret:
                    break
                
                # æ›´æ–°è¿›åº¦
                frame_count += 1
                progress = frame_count / total_frames
                progress_bar.progress(progress)
                status_text.text(f"å¤„ç†å¸§: {frame_count}/{total_frames}")
                
                # æ¯éš”å‡ å¸§è¿›è¡Œä¸€æ¬¡æ£€æµ‹
                if frame_count % 3 == 0:  # å¯ä»¥è°ƒæ•´æ£€æµ‹é¢‘ç‡
                    # è¿›è¡Œæ£€æµ‹
                    results = model(frame, conf=confidence, iou=iou_threshold, max_det=max_det)
                    
                    for result in results:
                        frame = result.plot()
                        boxes = result.boxes
                        num_detections = len(boxes)
                        
                        # è®°å½•æ£€æµ‹ç»“æœ
                        detection_results.append({
                            'frame': frame_count,
                            'detections': num_detections,
                            'confidences': [box.conf.item() for box in boxes]
                        })
                
                # æ˜¾ç¤ºå¤„ç†åçš„å¸§
                frame_placeholder.image(frame, channels="BGR", caption=f"Frame {frame_count}")
                
                # æ˜¾ç¤ºå®æ—¶ç»Ÿè®¡
                if detection_results:
                    avg_detections = np.mean([r['detections'] for r in detection_results])
                    stats_placeholder.markdown(f"""
                    ### ğŸ“Š è§†é¢‘å¤„ç†ç»Ÿè®¡
                    - å½“å‰å¸§: {frame_count}/{total_frames}
                    - å¹³å‡æ£€æµ‹æ•°: {avg_detections:.2f}
                    - å¤„ç†è¿›åº¦: {(frame_count/total_frames)*100:.1f}%
                    """)
            
            # é‡Šæ”¾èµ„æº
            cap.release()
            os.remove(video_path)  # åˆ é™¤ä¸´æ—¶è§†é¢‘æ–‡ä»¶
            
            # æ˜¾ç¤ºæœ€ç»ˆç»Ÿè®¡
            st.success("âœ… è§†é¢‘å¤„ç†å®Œæˆï¼")
            
            # åˆ›å»ºæ£€æµ‹ç»“æœDataFrame
            df = pd.DataFrame(detection_results)

st.markdown("---")
st.markdown("ç¬¬äºŒå°ç»„ | æœ€åæ›´æ–°æ—¶é—´: " + datetime.now().strftime("%Y-%m-%d %H:%M:%S"))
